{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0437f41",
   "metadata": {},
   "source": [
    "# CellSimul Conditional GAN Training in Google Colab\n",
    "\n",
    "This notebook allows you to train the CellSimul conditional GAN for fluorescent microscopy image generation using Google Colab's free GPU resources.\n",
    "\n",
    "## Features:\n",
    "- ðŸš€ Free GPU training with Google Colab\n",
    "- ðŸ“¦ Automatic repository installation\n",
    "- ðŸŽ¯ Conditional GAN training with real fluorescent + synthetic distance masks\n",
    "- ðŸ“Š Real-time training visualization\n",
    "- ðŸ’¾ Easy model and sample saving to Google Drive\n",
    "\n",
    "## Requirements:\n",
    "- Google account for Colab access\n",
    "- Your fluorescent images and distance masks (can be uploaded or mounted from Drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ab55b",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 1: Setup Environment and Install Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcff0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected. Training will be slow on CPU.\")\n",
    "    print(\"ðŸ’¡ Enable GPU: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib pillow tifffile scikit-image\n",
    "!pip install -q ipywidgets tqdm\n",
    "\n",
    "print(\"âœ… Required packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the CellSimul repository\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('CellSimul'):\n",
    "    !rm -rf CellSimul\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/Cetus137/CellSimul.git\n",
    "\n",
    "# Navigate to the repository\n",
    "os.chdir('CellSimul/CellSimul')\n",
    "\n",
    "# Add to Python path\n",
    "if '/content/CellSimul/CellSimul' not in sys.path:\n",
    "    sys.path.append('/content/CellSimul/CellSimul')\n",
    "    sys.path.append('/content/CellSimul/CellSimul/cond_models')\n",
    "\n",
    "print(f\"âœ… Repository cloned successfully!\")\n",
    "print(f\"ðŸ“ Current directory: {os.getcwd()}\")\n",
    "print(f\"ðŸ“‚ Contents: {os.listdir('.')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ee6e8",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Step 2: Data Setup\n",
    "\n",
    "You have several options for getting your data into Colab:\n",
    "\n",
    "### Option A: Mount Google Drive (Recommended)\n",
    "If your data is already in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ea2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set paths to your data in Google Drive\n",
    "# Adjust these paths to match your Google Drive structure\n",
    "DRIVE_DATA_PATH = '/content/drive/MyDrive/CellSimul_Data'  # Adjust this path\n",
    "FLUORESCENCE_DIR = f'{DRIVE_DATA_PATH}/fluorescence_rescaled'\n",
    "DISTANCE_MASKS_DIR = f'{DRIVE_DATA_PATH}/distance_masks_rescaled'\n",
    "\n",
    "print(f\"ðŸ“ Drive mounted! Looking for data at:\")\n",
    "print(f\"  Fluorescence: {FLUORESCENCE_DIR}\")\n",
    "print(f\"  Distance masks: {DISTANCE_MASKS_DIR}\")\n",
    "\n",
    "# Check if directories exist\n",
    "if os.path.exists(FLUORESCENCE_DIR):\n",
    "    fluor_files = len([f for f in os.listdir(FLUORESCENCE_DIR) if f.endswith(('.tif', '.tiff'))])\n",
    "    print(f\"âœ… Found {fluor_files} fluorescence images\")\n",
    "else:\n",
    "    print(f\"âŒ Fluorescence directory not found: {FLUORESCENCE_DIR}\")\n",
    "\n",
    "if os.path.exists(DISTANCE_MASKS_DIR):\n",
    "    mask_files = len([f for f in os.listdir(DISTANCE_MASKS_DIR) if f.endswith(('.tif', '.tiff'))])\n",
    "    print(f\"âœ… Found {mask_files} distance mask images\")\n",
    "else:\n",
    "    print(f\"âŒ Distance masks directory not found: {DISTANCE_MASKS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc1c63",
   "metadata": {},
   "source": [
    "### Option B: Upload Files Directly\n",
    "If you want to upload files directly to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cd405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Upload files directly (uncomment if not using Google Drive)\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "\n",
    "# # Create data directories\n",
    "# os.makedirs('data/fluorescence_rescaled', exist_ok=True)\n",
    "# os.makedirs('data/distance_masks_rescaled', exist_ok=True)\n",
    "\n",
    "# print(\"ðŸ“¤ Upload your data files:\")\n",
    "# print(\"1. Fluorescence images (TIF files)\")\n",
    "# print(\"2. Distance mask images (TIF files)\")\n",
    "# print(\"3. Or upload ZIP files containing the images\")\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Extract ZIP files if uploaded\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('data/')\n",
    "#         print(f\"âœ… Extracted {filename}\")\n",
    "\n",
    "# FLUORESCENCE_DIR = 'data/fluorescence_rescaled'\n",
    "# DISTANCE_MASKS_DIR = 'data/distance_masks_rescaled'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3238059",
   "metadata": {},
   "source": [
    "### Option C: Use Sample Data (for testing)\n",
    "Generate synthetic sample data for testing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b17404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option C: Generate sample data for testing (uncomment if needed)\n",
    "# import numpy as np\n",
    "# import tifffile\n",
    "# from PIL import Image\n",
    "\n",
    "# # Create sample data directories\n",
    "# os.makedirs('data/fluorescence_rescaled', exist_ok=True)\n",
    "# os.makedirs('data/distance_masks_rescaled', exist_ok=True)\n",
    "\n",
    "# print(\"ðŸ§ª Generating synthetic sample data for testing...\")\n",
    "\n",
    "# # Generate 50 sample images\n",
    "# for i in range(50):\n",
    "#     # Synthetic fluorescent image\n",
    "#     fluor_img = np.random.rand(256, 256) * 255\n",
    "#     fluor_img = fluor_img.astype(np.uint8)\n",
    "#     tifffile.imwrite(f'data/fluorescence_rescaled/sample_fluor_{i:03d}.tif', fluor_img)\n",
    "    \n",
    "#     # Synthetic distance mask\n",
    "#     x, y = np.meshgrid(np.arange(256), np.arange(256))\n",
    "#     center_x, center_y = np.random.randint(64, 192, 2)\n",
    "#     distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "#     mask = np.exp(-distance / 30)  # Exponential decay\n",
    "#     mask = (mask * 255).astype(np.uint8)\n",
    "#     tifffile.imwrite(f'data/distance_masks_rescaled/sample_mask_{i:03d}.tif', mask)\n",
    "\n",
    "# FLUORESCENCE_DIR = 'data/fluorescence_rescaled'\n",
    "# DISTANCE_MASKS_DIR = 'data/distance_masks_rescaled'\n",
    "# print(\"âœ… Sample data generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b59b41",
   "metadata": {},
   "source": [
    "## ðŸ” Step 3: Verify Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data setup\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "# Check data directories\n",
    "if not os.path.exists(FLUORESCENCE_DIR):\n",
    "    print(f\"âŒ Error: Fluorescence directory not found: {FLUORESCENCE_DIR}\")\n",
    "    print(\"Please set up your data using one of the options above.\")\n",
    "else:\n",
    "    fluor_files = [f for f in os.listdir(FLUORESCENCE_DIR) if f.endswith(('.tif', '.tiff'))]\n",
    "    print(f\"âœ… Found {len(fluor_files)} fluorescence images\")\n",
    "\n",
    "if not os.path.exists(DISTANCE_MASKS_DIR):\n",
    "    print(f\"âŒ Error: Distance masks directory not found: {DISTANCE_MASKS_DIR}\")\n",
    "    print(\"Please set up your data using one of the options above.\")\n",
    "else:\n",
    "    mask_files = [f for f in os.listdir(DISTANCE_MASKS_DIR) if f.endswith(('.tif', '.tiff'))]\n",
    "    print(f\"âœ… Found {len(mask_files)} distance mask images\")\n",
    "\n",
    "# Visualize sample data\n",
    "if os.path.exists(FLUORESCENCE_DIR) and os.path.exists(DISTANCE_MASKS_DIR):\n",
    "    if fluor_files and mask_files:\n",
    "        # Load sample images\n",
    "        sample_fluor = tifffile.imread(os.path.join(FLUORESCENCE_DIR, fluor_files[0]))\n",
    "        sample_mask = tifffile.imread(os.path.join(DISTANCE_MASKS_DIR, mask_files[0]))\n",
    "        \n",
    "        # Plot samples\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(sample_fluor, cmap='green')\n",
    "        axes[0].set_title('Sample Fluorescent Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(sample_mask, cmap='hot')\n",
    "        axes[1].set_title('Sample Distance Mask')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        overlay = np.stack([sample_mask/255, sample_fluor/255, np.zeros_like(sample_mask)/255], axis=-1)\n",
    "        axes[2].imshow(overlay)\n",
    "        axes[2].set_title('Overlay (Red=Mask, Green=Fluorescent)')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"ðŸ“Š Image info:\")\n",
    "        print(f\"  Fluorescent shape: {sample_fluor.shape}\")\n",
    "        print(f\"  Distance mask shape: {sample_mask.shape}\")\n",
    "        print(f\"  Fluorescent range: [{sample_fluor.min()}, {sample_fluor.max()}]\")\n",
    "        print(f\"  Distance mask range: [{sample_mask.min()}, {sample_mask.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade1e42",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 4: Import and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CellSimul models and training components\n",
    "try:\n",
    "    # Change to the models directory\n",
    "    os.chdir('cond_models')\n",
    "    \n",
    "    # Import models\n",
    "    from conditional_generator import ConditionalGenerator, SimpleConditionalGenerator\n",
    "    from conditional_discriminator import ConditionalDiscriminator, SimpleConditionalDiscriminator\n",
    "    from unpaired_conditional_dataloader import UnpairedConditionalImageDataset\n",
    "    \n",
    "    print(\"âœ… Successfully imported CellSimul models!\")\n",
    "    \n",
    "    # Test model initialization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ðŸŽ¯ Using device: {device}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = ConditionalGenerator().to(device)\n",
    "    discriminator = ConditionalDiscriminator().to(device)\n",
    "    \n",
    "    print(f\"ðŸ§  Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"ðŸ§  Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    with torch.no_grad():\n",
    "        test_noise = torch.randn(1, 100, device=device)\n",
    "        test_mask = torch.randn(1, 1, 256, 256, device=device)\n",
    "        test_generated = generator(test_noise, test_mask)\n",
    "        test_discriminator_out = discriminator(test_generated, test_mask)\n",
    "        \n",
    "        print(f\"âœ… Model test successful!\")\n",
    "        print(f\"  Generated image shape: {test_generated.shape}\")\n",
    "        print(f\"  Discriminator output shape: {test_discriminator_out.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error importing models: {e}\")\n",
    "    print(\"\\nTrying to debug...\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Directory contents: {os.listdir('.')}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72c3ed",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Create Dataset and Test Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "try:\n",
    "    # Go back to main directory for data access\n",
    "    os.chdir('..')\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = UnpairedConditionalImageDataset(\n",
    "        fluorescent_dir=FLUORESCENCE_DIR,\n",
    "        mask_dir=DISTANCE_MASKS_DIR,\n",
    "        image_size=256,\n",
    "        max_images=100  # Limit for faster testing\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Dataset created successfully!\")\n",
    "    print(f\"ðŸ“Š Dataset size: {len(dataset)}\")\n",
    "    \n",
    "    # Test data loading\n",
    "    sample_fluor, sample_mask = dataset[0]\n",
    "    print(f\"ðŸ“ Sample shapes - Fluorescent: {sample_fluor.shape}, Mask: {sample_mask.shape}\")\n",
    "    print(f\"ðŸ“ˆ Sample ranges - Fluorescent: [{sample_fluor.min():.3f}, {sample_fluor.max():.3f}], Mask: [{sample_mask.min():.3f}, {sample_mask.max():.3f}]\")\n",
    "    \n",
    "    # Create dataloader\n",
    "    from torch.utils.data import DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)  # num_workers=0 for Colab\n",
    "    \n",
    "    # Test batch loading\n",
    "    batch_fluor, batch_mask = next(iter(dataloader))\n",
    "    print(f\"âœ… Batch loading successful!\")\n",
    "    print(f\"ðŸ“¦ Batch shapes - Fluorescent: {batch_fluor.shape}, Mask: {batch_mask.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating dataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750eb66e",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 6: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02799041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,  # Reduced for Colab time limits\n",
    "    'learning_rate': 0.0002,\n",
    "    'save_frequency': 5,  # Save samples every 5 epochs\n",
    "    'model_type': 'complex',  # or 'simple' for faster training\n",
    "    'max_images': None,  # Use all available images, or set a number for faster training\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "print(\"ðŸŽ¯ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'colab_outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"\\nðŸ“ Output directory: {output_dir}\")\n",
    "\n",
    "# Estimate training time\n",
    "estimated_time_per_epoch = len(dataset) // TRAINING_CONFIG['batch_size'] * 2  # seconds\n",
    "total_estimated_time = estimated_time_per_epoch * TRAINING_CONFIG['num_epochs'] / 60  # minutes\n",
    "print(f\"\\nâ±ï¸ Estimated training time: {total_estimated_time:.1f} minutes\")\n",
    "\n",
    "if total_estimated_time > 60:\n",
    "    print(\"âš ï¸ Training might take more than 1 hour. Consider reducing num_epochs or using max_images for faster training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0ec2a",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 7: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function (simplified version of the training script)\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train_conditional_gan(config):\n",
    "    \"\"\"Train the conditional GAN with the given configuration.\"\"\"\n",
    "    \n",
    "    # Create fresh dataset with config\n",
    "    dataset = UnpairedConditionalImageDataset(\n",
    "        fluorescent_dir=FLUORESCENCE_DIR,\n",
    "        mask_dir=DISTANCE_MASKS_DIR,\n",
    "        image_size=256,\n",
    "        max_images=config['max_images']\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=config['batch_size'], \n",
    "        shuffle=True, \n",
    "        num_workers=0  # Must be 0 in Colab\n",
    "    )\n",
    "    \n",
    "    # Initialize models\n",
    "    if config['model_type'] == 'simple':\n",
    "        generator = SimpleConditionalGenerator().to(config['device'])\n",
    "        discriminator = SimpleConditionalDiscriminator().to(config['device'])\n",
    "    else:\n",
    "        generator = ConditionalGenerator().to(config['device'])\n",
    "        discriminator = ConditionalDiscriminator().to(config['device'])\n",
    "    \n",
    "    # Optimizers\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=config['learning_rate'], betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=config['learning_rate']*0.5, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Loss functions\n",
    "    adversarial_criterion = nn.BCELoss()\n",
    "    identity_criterion = nn.L1Loss()\n",
    "    \n",
    "    # Training tracking\n",
    "    training_history = {\n",
    "        'g_losses': [],\n",
    "        'd_losses': [],\n",
    "        'adv_losses': [],\n",
    "        'identity_losses': []\n",
    "    }\n",
    "    \n",
    "    print(f\"ðŸš€ Starting training on {len(dataset)} images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        epoch_g_loss = 0.0\n",
    "        epoch_d_loss = 0.0\n",
    "        epoch_adv_loss = 0.0\n",
    "        epoch_identity_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Progress bar for the epoch\n",
    "        pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]}')\n",
    "        \n",
    "        for batch_idx, (real_fluorescent, condition_masks) in enumerate(pbar):\n",
    "            real_fluorescent = real_fluorescent.to(config['device'])\n",
    "            condition_masks = condition_masks.to(config['device'])\n",
    "            batch_size = real_fluorescent.size(0)\n",
    "            \n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            z = torch.randn(batch_size, 100, device=config['device'])\n",
    "            generated_fluorescent = generator(z, condition_masks)\n",
    "            \n",
    "            # Identity loss (structure preservation)\n",
    "            identity_loss = identity_criterion(generated_fluorescent, real_fluorescent) * 0.1\n",
    "            \n",
    "            # Adversarial loss\n",
    "            d_output_fake = discriminator(generated_fluorescent, condition_masks)\n",
    "            if d_output_fake.dim() > 2:\n",
    "                d_output_fake = d_output_fake.view(batch_size, -1).mean(dim=1)\n",
    "            \n",
    "            valid_labels = torch.ones(batch_size, device=config['device'])\n",
    "            adversarial_loss = adversarial_criterion(d_output_fake, valid_labels)\n",
    "            \n",
    "            g_loss = adversarial_loss + identity_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # Real samples\n",
    "            d_output_real = discriminator(real_fluorescent, condition_masks)\n",
    "            if d_output_real.dim() > 2:\n",
    "                d_output_real = d_output_real.view(batch_size, -1).mean(dim=1)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, device=config['device'])\n",
    "            d_real_loss = adversarial_criterion(d_output_real, real_labels)\n",
    "            \n",
    "            # Fake samples\n",
    "            d_output_fake_for_d = discriminator(generated_fluorescent.detach(), condition_masks)\n",
    "            if d_output_fake_for_d.dim() > 2:\n",
    "                d_output_fake_for_d = d_output_fake_for_d.view(batch_size, -1).mean(dim=1)\n",
    "            \n",
    "            fake_labels = torch.zeros(batch_size, device=config['device'])\n",
    "            d_fake_loss = adversarial_criterion(d_output_fake_for_d, fake_labels)\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_adv_loss += adversarial_loss.item()\n",
    "            epoch_identity_loss += identity_loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'G_loss': f'{g_loss.item():.3f}',\n",
    "                'D_loss': f'{d_loss.item():.3f}',\n",
    "                'Adv': f'{adversarial_loss.item():.3f}',\n",
    "                'Id': f'{identity_loss.item():.3f}'\n",
    "            })\n",
    "        \n",
    "        # Epoch summary\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_adv_loss = epoch_adv_loss / num_batches\n",
    "        avg_identity_loss = epoch_identity_loss / num_batches\n",
    "        \n",
    "        training_history['g_losses'].append(avg_g_loss)\n",
    "        training_history['d_losses'].append(avg_d_loss)\n",
    "        training_history['adv_losses'].append(avg_adv_loss)\n",
    "        training_history['identity_losses'].append(avg_identity_loss)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Epoch {epoch+1} Summary:\")\n",
    "        print(f\"  G_loss: {avg_g_loss:.4f}, D_loss: {avg_d_loss:.4f}\")\n",
    "        print(f\"  Adv_loss: {avg_adv_loss:.4f}, Identity_loss: {avg_identity_loss:.4f}\")\n",
    "        \n",
    "        # Save samples\n",
    "        if (epoch + 1) % config['save_frequency'] == 0:\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                sample_z = torch.randn(4, 100, device=config['device'])\n",
    "                sample_mask = condition_masks[:4]\n",
    "                sample_generated = generator(sample_z, sample_mask)\n",
    "                \n",
    "                save_image(\n",
    "                    sample_generated,\n",
    "                    f'{output_dir}/samples_epoch_{epoch+1:03d}.png',\n",
    "                    normalize=True,\n",
    "                    nrow=2\n",
    "                )\n",
    "                print(f\"ðŸ’¾ Saved sample images for epoch {epoch+1}\")\n",
    "            generator.train()\n",
    "    \n",
    "    # Save final models\n",
    "    torch.save(generator.state_dict(), f'{output_dir}/final_generator.pth')\n",
    "    torch.save(discriminator.state_dict(), f'{output_dir}/final_discriminator.pth')\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nðŸŽ‰ Training completed in {total_time/60:.1f} minutes!\")\n",
    "    \n",
    "    return training_history, generator, discriminator\n",
    "\n",
    "print(\"âœ… Training function defined and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8538b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "print(\"ðŸš€ Starting Conditional GAN Training...\")\n",
    "print(\"âš ï¸  This may take a while. You can monitor progress with the progress bars.\")\n",
    "print(\"ðŸ“± Colab may disconnect after ~12 hours. Consider shorter training runs.\")\n",
    "\n",
    "# Run training\n",
    "training_history, trained_generator, trained_discriminator = train_conditional_gan(TRAINING_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f40d50",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 8: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Generator and Discriminator losses\n",
    "axes[0, 0].plot(training_history['g_losses'], label='Generator Loss', color='blue')\n",
    "axes[0, 0].plot(training_history['d_losses'], label='Discriminator Loss', color='red')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Generator vs Discriminator Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adversarial loss\n",
    "axes[0, 1].plot(training_history['adv_losses'], label='Adversarial Loss', color='green')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Adversarial Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Identity loss\n",
    "axes[1, 0].plot(training_history['identity_losses'], label='Identity Loss', color='orange')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('Identity Loss (Structure Preservation)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss ratio (training balance)\n",
    "if len(training_history['g_losses']) > 0 and len(training_history['d_losses']) > 0:\n",
    "    loss_ratios = [g/(d+1e-8) for g, d in zip(training_history['g_losses'], training_history['d_losses'])]\n",
    "    axes[1, 1].plot(loss_ratios, label='G_loss / D_loss', color='purple')\n",
    "    axes[1, 1].axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Balanced (ratio=1)')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss Ratio')\n",
    "    axes[1, 1].set_title('Training Balance')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ˆ Training history plotted and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da206a1c",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Step 9: Generate and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c146ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new samples with the trained model\n",
    "trained_generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get some real samples for comparison\n",
    "    real_fluor, real_masks = next(iter(dataloader))\n",
    "    real_fluor = real_fluor[:4].to(device)\n",
    "    real_masks = real_masks[:4].to(device)\n",
    "    \n",
    "    # Generate new samples using the real masks\n",
    "    z = torch.randn(4, 100, device=device)\n",
    "    generated_fluor = trained_generator(z, real_masks)\n",
    "    \n",
    "    # Convert to numpy for visualization\n",
    "    real_fluor_np = real_fluor.cpu().numpy()\n",
    "    real_masks_np = real_masks.cpu().numpy()\n",
    "    generated_fluor_np = generated_fluor.cpu().numpy()\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    \n",
    "    for i in range(4):\n",
    "        # Real masks\n",
    "        axes[0, i].imshow(real_masks_np[i, 0], cmap='hot')\n",
    "        axes[0, i].set_title(f'Distance Mask {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Real fluorescent\n",
    "        real_img = (real_fluor_np[i, 0] + 1) / 2  # Denormalize\n",
    "        axes[1, i].imshow(real_img, cmap='green')\n",
    "        axes[1, i].set_title(f'Real Fluorescent {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Generated fluorescent\n",
    "        gen_img = (generated_fluor_np[i, 0] + 1) / 2  # Denormalize\n",
    "        axes[2, i].imshow(gen_img, cmap='green')\n",
    "        axes[2, i].set_title(f'Generated Fluorescent {i+1}')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Conditional GAN Results: Distance Masks â†’ Generated Fluorescent Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/final_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ðŸŽ¨ Generated new fluorescent images conditioned on distance masks!\")\n",
    "    print(f\"ðŸ’¾ Results saved to {output_dir}/final_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35512306",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 10: Save Results to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to Google Drive (if mounted)\n",
    "try:\n",
    "    if os.path.exists('/content/drive/MyDrive'):\n",
    "        import shutil\n",
    "        \n",
    "        # Create output directory in Drive\n",
    "        drive_output_dir = '/content/drive/MyDrive/CellSimul_Training_Results'\n",
    "        os.makedirs(drive_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy all output files\n",
    "        for file in os.listdir(output_dir):\n",
    "            src = os.path.join(output_dir, file)\n",
    "            dst = os.path.join(drive_output_dir, file)\n",
    "            shutil.copy2(src, dst)\n",
    "        \n",
    "        print(f\"âœ… Results copied to Google Drive: {drive_output_dir}\")\n",
    "        print(\"ðŸ“ Saved files:\")\n",
    "        for file in os.listdir(drive_output_dir):\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ Google Drive not mounted. Results are saved locally in Colab.\")\n",
    "        print(\"âš ï¸ Remember that Colab files are temporary and will be lost when the session ends.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error saving to Drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd0042",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Step 11: Download Results (Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results as ZIP file\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Create ZIP file with all results\n",
    "zip_filename = 'cellsimul_training_results.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    for root, dirs, files_list in os.walk(output_dir):\n",
    "        for file in files_list:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, output_dir)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"ðŸ“¦ Created {zip_filename} with all training results\")\n",
    "print(f\"ðŸ“Š ZIP file size: {os.path.getsize(zip_filename) / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Download the ZIP file\n",
    "print(\"â¬‡ï¸ Downloading results...\")\n",
    "files.download(zip_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b517775",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 12: Using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use the trained model for inference\n",
    "def generate_fluorescent_from_mask(generator, distance_mask, device, num_variations=4):\n",
    "    \"\"\"\n",
    "    Generate fluorescent images from a distance mask.\n",
    "    \n",
    "    Args:\n",
    "        generator: Trained generator model\n",
    "        distance_mask: Input distance mask (numpy array or tensor)\n",
    "        device: Device to run inference on\n",
    "        num_variations: Number of different generations from the same mask\n",
    "    \n",
    "    Returns:\n",
    "        Generated fluorescent images\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare mask tensor\n",
    "        if isinstance(distance_mask, np.ndarray):\n",
    "            mask_tensor = torch.from_numpy(distance_mask).float()\n",
    "        else:\n",
    "            mask_tensor = distance_mask.float()\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        if mask_tensor.dim() == 2:\n",
    "            mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "        elif mask_tensor.dim() == 3:\n",
    "            mask_tensor = mask_tensor.unsqueeze(0)  # Add batch dim\n",
    "        \n",
    "        # Repeat for multiple variations\n",
    "        mask_batch = mask_tensor.repeat(num_variations, 1, 1, 1).to(device)\n",
    "        \n",
    "        # Generate random noise\n",
    "        noise = torch.randn(num_variations, 100, device=device)\n",
    "        \n",
    "        # Generate fluorescent images\n",
    "        generated = generator(noise, mask_batch)\n",
    "        \n",
    "        return generated\n",
    "\n",
    "# Example usage\n",
    "print(\"ðŸ§ª Testing inference with trained model...\")\n",
    "\n",
    "# Get a sample mask\n",
    "sample_mask = real_masks[0:1]  # Take first mask\n",
    "\n",
    "# Generate variations\n",
    "variations = generate_fluorescent_from_mask(trained_generator, sample_mask, device, num_variations=6)\n",
    "\n",
    "# Visualize variations\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Show original mask\n",
    "axes[0, 0].imshow(sample_mask[0, 0].cpu().numpy(), cmap='hot')\n",
    "axes[0, 0].set_title('Input Distance Mask')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Show variations\n",
    "for i in range(6):\n",
    "    row = i // 3\n",
    "    col = (i % 3) + 1\n",
    "    \n",
    "    if col > 3:\n",
    "        row = 1\n",
    "        col = i % 3\n",
    "    \n",
    "    gen_img = (variations[i, 0].cpu().numpy() + 1) / 2  # Denormalize\n",
    "    axes[row, col].imshow(gen_img, cmap='green')\n",
    "    axes[row, col].set_title(f'Generated Variation {i+1}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "# Clear unused subplot\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "plt.suptitle('Single Distance Mask â†’ Multiple Fluorescent Variations', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/inference_example.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Inference example completed!\")\n",
    "print(\"ðŸŽ¯ The trained model can generate diverse fluorescent images from the same distance mask.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f173f16",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Summary and Next Steps\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You have successfully:\n",
    "\n",
    "âœ… Set up the CellSimul environment in Google Colab  \n",
    "âœ… Loaded your fluorescent microscopy data  \n",
    "âœ… Trained a conditional GAN model  \n",
    "âœ… Generated realistic fluorescent images from distance masks  \n",
    "âœ… Saved and visualized your results  \n",
    "\n",
    "### ðŸ”„ **To run more training:**\n",
    "- Adjust `TRAINING_CONFIG` parameters above\n",
    "- Re-run the training cell\n",
    "- Try different model types (`simple` vs `complex`)\n",
    "\n",
    "### ðŸ“ˆ **To improve results:**\n",
    "- Increase `num_epochs` for longer training\n",
    "- Adjust `learning_rate` if training is unstable\n",
    "- Use more training data if available\n",
    "- Experiment with different loss weightings\n",
    "\n",
    "### ðŸ’¾ **Your trained models are saved as:**\n",
    "- `final_generator.pth` - The trained generator\n",
    "- `final_discriminator.pth` - The trained discriminator\n",
    "- Sample images and training plots\n",
    "\n",
    "### ðŸš€ **Next steps:**\n",
    "- Use the trained model to generate synthetic training data\n",
    "- Fine-tune on specific cell types or conditions\n",
    "- Integrate into your research pipeline\n",
    "- Share results with collaborators\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Check the [CellSimul repository](https://github.com/Cetus137/CellSimul) for documentation and examples!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
